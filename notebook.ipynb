{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_file = 'ml-latest-small/ratings.csv'\n",
    "movies_file = 'ml-latest-small/movies.csv'\n",
    "ratings_data = pd.read_csv(ratings_file)\n",
    "movies_data = pd.read_csv(movies_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(ratings_data, movies_data):\n",
    "    # merge ratings and movies data based on movieId\n",
    "    merged_data = pd.merge(ratings_data, movies_data, on='movieId')\n",
    "    # drop rows with missing values\n",
    "    merged_data.dropna(inplace=True)\n",
    "    # feature engineering\n",
    "    merged_data['total_ratings'] = merged_data.groupby('movieId')['rating'].transform('count')\n",
    "    # normalization ratings feature\n",
    "    scaler = MinMaxScaler()\n",
    "    merged_data[['rating', 'total_ratings']] = scaler.fit_transform(merged_data[['rating', 'total_ratings']])\n",
    "    # handle categorical featire (genres)\n",
    "    encoded_genres = pd.get_dummies(merged_data['genres'], prefix='genre')\n",
    "    merged_data = pd.concat([merged_data, encoded_genres], axis=1)\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained gpt2 model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_text_with_gpt2(text, tokenizer):\n",
    "    # tokenization using GPT-2 tokenizer\n",
    "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    return encoded_input\n",
    "\n",
    "def encoding_movie_attributes_with_gpt(movie_attributes):\n",
    "    if movie_attributes is None or len(movie_attributes) == 0:\n",
    "        return None\n",
    "\n",
    "    # Find the maximum length in the batch\n",
    "    max_length = max(len(attr) for attr in movie_attributes)\n",
    "\n",
    "    encoded_attributes = []\n",
    "    for attr in movie_attributes:\n",
    "        encoded_input = tokenizer.encode_plus(attr, add_special_tokens=True, return_tensors='pt')\n",
    "        encoded_attributes.append(encoded_input['input_ids'].squeeze(0))\n",
    "\n",
    "    # Pad each sequence individually to the maximum length\n",
    "    padded_attributes = []\n",
    "    for attr in encoded_attributes:\n",
    "        padded_attr = torch.nn.functional.pad(attr, (0, max_length - attr.size(0)), value=0)  # Set padding value to 0\n",
    "        padded_attributes.append(padded_attr)\n",
    "\n",
    "    # Stack the padded sequences\n",
    "    encoded_attributes = torch.stack(padded_attributes, dim=0)\n",
    "\n",
    "    return encoded_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_movie_attributes(movie_ids, movie_titles, movie_genres):\n",
    "    preprocessed_attributes = []\n",
    "    for movie_id, title, genre in zip(movie_ids, movie_titles, movie_genres):\n",
    "        # convert genre to a list\n",
    "        genre_list = [genre.strip() for genre in genre.split(',')]\n",
    "        # join the attributes into a single string\n",
    "        combined_attr = f\"{movie_id}, {title}, {', '.join(genre_list)}\"\n",
    "        preprocessed_attributes.append(combined_attr)\n",
    "\n",
    "    return preprocessed_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_similarity_scores(encoded_attributes):\n",
    "    similarity_matrix = []\n",
    "    for attr in encoded_attributes:\n",
    "        attr = attr.squeeze(0)\n",
    "        # calculate cosine similarity between attribute and all other attributes\n",
    "        similarity_scores = torch.cosine_similarity(attr.unsqueeze(0).float(), encoded_attributes.squeeze(1).float(), dim=1)\n",
    "        similarity_matrix.append(similarity_scores)\n",
    "    similarity_matrix = torch.stack(similarity_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(movie_id, similarity_matrix, movie_ids, top_n=5):\n",
    "    # get the index of the movie in the movie_ids list\n",
    "    movie_index = movie_ids.index(movie_id)\n",
    "    # get the similarity scores of the given movie with other movies\n",
    "    movie_scores = similarity_matrix[movie_index]\n",
    "    # sort the movie scores in descending order and get the top N movies\n",
    "    top_movie_indices = sorted(range(len(movie_scores)), key=lambda i: movie_scores[i], reverse=True)[:top_n]\n",
    "    # retrieve the movie IDs of the top recommended movies\n",
    "    recommended_movie_ids = [movie_ids[index] for index in top_movie_indices]\n",
    "    return recommended_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_user_input(user_input):\n",
    "    movie_preferences = []\n",
    "    keywords = []\n",
    "    # Split the user input into individual tokens\n",
    "    tokens = user_input.lower().split()\n",
    "    # Logic for extracting preferences and keywords\n",
    "    for index, token in enumerate(tokens):\n",
    "        if token in ['like', 'love', 'enjoy']:\n",
    "            # If the next token is 'movie' or 'movies', capture preferences\n",
    "            if index + 1 < len(tokens) and tokens[index + 1] in ['movie', 'movies']:\n",
    "                movie_preferences.append(token)\n",
    "            else:\n",
    "                keywords.append(token)\n",
    "        elif token in ['recommend', 'similar', 'recommendation']:\n",
    "            # If the previous token is 'with', capture recommendation request\n",
    "            if index - 1 >= 0 and tokens[index - 1] == 'with':\n",
    "                keywords.append(token)\n",
    "        elif token == 'not':\n",
    "            # If the next token is 'like', capture preferences to avoid\n",
    "            if index + 1 < len(tokens) and tokens[index + 1] == 'like':\n",
    "                index += 1  # Skip the 'like' token after 'not'\n",
    "            else:\n",
    "                keywords.append(token)\n",
    "        else:\n",
    "            keywords.append(token)\n",
    "    \n",
    "    print(\"Movie Preferences:\", movie_preferences)\n",
    "    print(\"Keywords:\", keywords)\n",
    "    \n",
    "    return movie_preferences, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_specific_movie(user_input, movies_data):\n",
    "    encoded_input = preprocess_text_with_gpt2(user_input)\n",
    "    generated_output = model.generate(encoded_input['input_ids'], max_length=100)\n",
    "    generated_text = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Search for movie title in the generated text\n",
    "    for movie_title in movies_data['title']:\n",
    "        if movie_title.lower() in generated_text.lower():\n",
    "            return movie_title\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_movie_id_from_title(movie_title, movies_data):\n",
    "    movie = movies_data[movies_data['title'].str.lower() == movie_title]\n",
    "    if not movie.empty:\n",
    "        movie_id = movie['movieId'].values[0]\n",
    "        return movie_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_movies_by_keywords(keywords, movie_ids, movie_attributes):\n",
    "    matched_movies = []\n",
    "    for movie_id, attributes in zip(movie_ids, movie_attributes):\n",
    "        attributes = [attr.lower() for attr in attributes]\n",
    "        keywords = [keyword.lower() for keyword in keywords]\n",
    "        # perform partial matching\n",
    "        for keyword in keywords:\n",
    "            for attribute in attributes:\n",
    "                if keyword in attribute:\n",
    "                    matched_movies.append(movie_id)\n",
    "                    break\n",
    "    return matched_movies\n",
    "\n",
    "def get_movie_details(movie_id, movies_data):\n",
    "    movie = movies_data[movies_data['movieId'] == movie_id]\n",
    "    if not movie.empty:\n",
    "        title = movie['title'].values[0]\n",
    "        genre = movie['genres'].values[0]\n",
    "        return {\"title\": title, \"genre\": genre}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(movies_data, ratings_data, top_k=5):\n",
    "    user_preferences = input(\"Enter your movie preferences (comma-separated): \").lower().split(',')\n",
    "    # preprocess the data\n",
    "    data = preprocess_data(ratings_data,movies_data)\n",
    "    # preprocess movie attributes\n",
    "    movie_attributes = preprocess_movie_attributes(data['movieId'], data['title'], data['genres'])\n",
    "    # encode movie attributes with GPT-2\n",
    "    encoded_attributes = encoding_movie_attributes_with_gpt(movie_attributes)\n",
    "    if encoded_attributes is not None and encoded_attributes.size(0) > 0:\n",
    "        # compute similarity scores\n",
    "        similarity_matrix = movie_similarity_scores(encoded_attributes)\n",
    "        # match user preferences with movie attributes\n",
    "        matched_movies = match_movies_by_keywords(user_preferences, data['movieId'], movie_attributes)\n",
    "        # get content-based recommendations\n",
    "        recommended_movie_ids = get_content_based_recommendations(matched_movies, similarity_matrix, data['movieId'])\n",
    "        # retrieve movie details for recommended movies\n",
    "        recommendations = []\n",
    "        for movie_id in recommended_movie_ids:\n",
    "            movie_details = get_movie_details(movie_id, movies_data)\n",
    "            if movie_details:\n",
    "                recommendations.append(movie_details)\n",
    "        # display top-k recommendations\n",
    "        print(f\"\\nTop {top_k} Recommendations:\")\n",
    "        for i, movie in enumerate(recommendations[:top_k], start=1):\n",
    "            print(f\"\\nMovie {i}:\")\n",
    "            print(f\"Title: {movie['title']}\")\n",
    "            print(f\"Genre: {movie['genre']}\")\n",
    "        return recommendations[:top_k]\n",
    "    return None\n",
    "\n",
    "recommended_movies = recommend_movies(movies_data, ratings_data, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
