{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from imdb import IMDb\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch.nn.functional as F\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMDb data preprocessing and attribute extraction\n",
    "def preprocess_imdb_datasource():\n",
    "    # class to access the data\n",
    "    imdb_obj = IMDb()\n",
    "    movies = imdb_obj.get_top250_movies()\n",
    "    movie_ids = []\n",
    "    movie_titles = []\n",
    "    movie_genres = []\n",
    "    movie_actors = []\n",
    "    movie_directors = []\n",
    "    movie_plot_summaries = []\n",
    "    # attributes extractions\n",
    "    for movie in movies:\n",
    "        movie_ids.append(movie.movieID)\n",
    "        movie_titles.append(movie['title'])\n",
    "        if 'genres' in movie:\n",
    "            movie_genres.append(movie['genres'])\n",
    "        else:\n",
    "            movie_genres.append([])\n",
    "        if 'cast' in movie:\n",
    "            movie_actors.append([actor['name'] for actor in movie['cast']])\n",
    "        else:\n",
    "            movie_actors.append([])\n",
    "        if 'director' in movie:\n",
    "            movie_directors.append([director['name'] for director in movie['director']])\n",
    "        else:\n",
    "            movie_directors.append([])\n",
    "        if 'plot outline' in movie:\n",
    "            movie_plot_summaries.append(movie['plot outline'])\n",
    "        else:\n",
    "            movie_plot_summaries.append(\"\")\n",
    "\n",
    "    return movie_ids, movie_titles, movie_genres, movie_actors, movie_directors, movie_plot_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained gpt2 model and tokenizer\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess_text_with_gpt2(text):\n",
    "    # tokenize the input using gpt2 tokenizer\n",
    "    encoded_input = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    return encoded_input\n",
    "\n",
    "def preprocess_movie_attributes(movie_genres, movie_actors, movie_directors, movie_plot_summaries):\n",
    "    preprocessed_attributes = []\n",
    "    for genre, actors, directors, summary in zip(movie_genres, movie_actors, movie_directors, movie_plot_summaries):\n",
    "        # convert genre, actors, and directors to strings\n",
    "        genre_str = ', '.join(genre)\n",
    "        actors_str = ', '.join(actors)\n",
    "        directors_str = ', '.join(directors)\n",
    "        # concatenate the attributes into a single string\n",
    "        combined_attr = f\"{genre_str}, {actors_str}, {directors_str}, {summary}\"\n",
    "        preprocessed_attributes.append(combined_attr)\n",
    "    return preprocessed_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_movie_attributes_with_gpt(movie_attributes):\n",
    "    model.eval()\n",
    "    encoded_attributes = []\n",
    "    for attr in movie_attributes:\n",
    "        if not attr or (isinstance(attr, (list, tuple)) and all(value == '' for value in attr)):\n",
    "            continue\n",
    "        preprocessed_attr = preprocess_text_with_gpt2(attr)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=preprocessed_attr['input_ids'], attention_mask=preprocessed_attr['attention_mask'])\n",
    "        if hasattr(outputs, 'last_hidden_state') and outputs.last_hidden_state.size(1) > 0:\n",
    "            encoded_attr = outputs.last_hidden_state\n",
    "            encoded_attributes.append(encoded_attr)\n",
    "        else:\n",
    "            continue\n",
    "    return encoded_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute similarity scores\n",
    "def movie_similarity_scores(encoded_attributes):\n",
    "    similarity_matrix = []\n",
    "    for attr in encoded_attributes:\n",
    "        attr = attr.squeeze(0)\n",
    "        # Calculate cosine similarity between attribute and all other attributes\n",
    "        similarity_scores = F.cosine_similarity(attr, torch.stack(encoded_attributes).squeeze(1), dim=1)\n",
    "        similarity_matrix.append(similarity_scores)\n",
    "    similarity_matrix = torch.stack(similarity_matrix)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_based_recommendations(movie_id, similarity_matrix, movie_ids, top_n=5):\n",
    "    # Get the index of the movie in the movie_ids list\n",
    "    movie_index = movie_ids.index(movie_id)\n",
    "    # Get the similarity scores of the given movie with other movies\n",
    "    movie_scores = similarity_matrix[movie_index]\n",
    "    # Sort the movie scores in descending order and get the top N movies\n",
    "    top_movie_indices = sorted(range(len(movie_scores)), key=lambda i: movie_scores[i], reverse=True)[:top_n]\n",
    "    # Retrieve the movie IDs of the top recommended movies\n",
    "    recommended_movie_ids = [movie_ids[index] for index in top_movie_indices]\n",
    "    return recommended_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_user_input(user_input):\n",
    "    movie_preferences = []\n",
    "    keywords = []\n",
    "    # tokenization and preprocessing using gpt2 \n",
    "    tokenized_input = preprocess_text_with_gpt2(user_input)\n",
    "    # logic for extracting preferences and keywords\n",
    "    for index, token in enumerate(tokenized_input):\n",
    "        if token in ['like', 'love', 'enjoy']:\n",
    "            # i the next token is 'movie' or 'movies' to capture preferences\n",
    "            if index + 1 < len(tokenized_input) and tokenized_input[index + 1] in ['movie', 'movies']:\n",
    "                movie_preferences.append(token)\n",
    "            else:\n",
    "                keywords.append(token)\n",
    "        elif token in ['recommend', 'similar', 'recommendation']:\n",
    "            # if the previous token is 'with' to capture recommendation request\n",
    "            if index - 1 >= 0 and tokenized_input[index - 1] == 'with':\n",
    "                keywords.append(token)\n",
    "        elif token == 'not':\n",
    "            # if the next token is 'like' to capture preferences to avoid\n",
    "            if index + 1 < len(tokenized_input) and tokenized_input[index + 1] == 'like':\n",
    "                index += 1  # skip the 'like' token after 'not'\n",
    "            else:\n",
    "                keywords.append(token)\n",
    "        else:\n",
    "            keywords.append(token)\n",
    "    \n",
    "    return movie_preferences, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_specific_movie(user_input):\n",
    "    # tokenization and preprocessing using gpt2 \n",
    "    encoded_input = preprocess_text_with_gpt2(user_input)\n",
    "    # predictions using gpt2 model\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'])\n",
    "    # decode the generated output to get the movie title\n",
    "    movie_title = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return movie_title\n",
    "\n",
    "def get_movie_id_from_title(movie_title):\n",
    "    # retrieve the movie_id from IMDb data source\n",
    "    imdb_obj = IMDb()\n",
    "    movies = imdb_obj.search_movie(movie_title)\n",
    "    if movies:\n",
    "        first_movie = movies[0]\n",
    "        movie_id = first_movie.movieID\n",
    "        return movie_id\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_movies_by_keywords(keywords, movie_ids, movie_attributes):\n",
    "    matched_movies = []\n",
    "    for movie_id, attributes in zip(movie_ids, movie_attributes):\n",
    "        # if any of the keywords match the movie attributes\n",
    "        for keyword in keywords:\n",
    "            if keyword in attributes:\n",
    "                matched_movies.append(movie_id)\n",
    "                break\n",
    "\n",
    "    return matched_movies\n",
    "\n",
    "def get_movie_details(movie_id):\n",
    "    # retrieve the details of a movie based on its ID using IMDbPy\n",
    "    ia = IMDb()\n",
    "    movie = ia.get_movie(movie_id)\n",
    "    title = movie['title']\n",
    "    genre = \", \".join(movie['genres'])\n",
    "    actors = \", \".join([actor['name'] for actor in movie['cast']])\n",
    "    director = \", \".join([director['name'] for director in movie['directors']])\n",
    "    summary = movie['plot'][0] if movie['plot'] else None\n",
    "\n",
    "    return {\"title\": title, \"genre\": genre, \"actors\": actors, \"director\": director, \"summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids, movie_titles, movie_genres, movie_actors, movie_directors, movie_plot_summaries = preprocess_imdb_datasource()\n",
    "preprocessed_attributes = preprocess_movie_attributes(movie_genres, movie_actors, movie_directors, movie_plot_summaries)\n",
    "encoded_attributes = encoding_movie_attributes_with_gpt(preprocessed_attributes)\n",
    "if encoded_attributes:\n",
    "    similarity_matrix = movie_similarity_scores(encoded_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "match_movies_by_keywords() missing 1 required positional argument: 'movie_attributes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danar\\Documents\\GitHub\\ChatGPT\\notebook.ipynb Cell 11\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danar/Documents/GitHub/ChatGPT/notebook.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOKAY.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danar/Documents/GitHub/ChatGPT/notebook.ipynb#X14sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39melif\u001b[39;00m keywords:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danar/Documents/GitHub/ChatGPT/notebook.ipynb#X14sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# handle user keywords\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/danar/Documents/GitHub/ChatGPT/notebook.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     matched_movies \u001b[39m=\u001b[39m match_movies_by_keywords(keywords, movie_titles)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danar/Documents/GitHub/ChatGPT/notebook.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mif\u001b[39;00m matched_movies:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/danar/Documents/GitHub/ChatGPT/notebook.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         recommended_movie_ids \u001b[39m=\u001b[39m get_content_based_recommendations(matched_movies, similarity_matrix, movie_ids)\n",
      "\u001b[1;31mTypeError\u001b[0m: match_movies_by_keywords() missing 1 required positional argument: 'movie_attributes'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    movie_preferences, keywords = preprocess_user_input(user_input)\n",
    "    if movie_preferences:\n",
    "        print(\"Thank you for sharing your movie preferences!\")\n",
    "        response = input(\"Would you like to some movie recommendations based on your preferences? (yes/no): \")\n",
    "        if response.lower() in ['yes', 'y']:\n",
    "            matched_movies = match_movies_by_keywords(movie_preferences, movie_titles)\n",
    "            if matched_movies:\n",
    "                recommended_movie_ids = get_content_based_recommendations(matched_movies, similarity_matrix, movie_ids)\n",
    "                if recommended_movie_ids:\n",
    "                    print(\"Here are some recommended movies that may match your taste:\")\n",
    "                    for movie_id in recommended_movie_ids:\n",
    "                        movie_details = get_movie_details(movie_id)\n",
    "                        print(f\"Title: {movie_details['title']}\")\n",
    "                        print(f\"Genre: {movie_details['genre']}\")\n",
    "                        print(f\"Actors: {movie_details['actors']}\")\n",
    "                        print(f\"Director: {movie_details['director']}\")\n",
    "                        print(f\"Summary: {movie_details['summary']}\")\n",
    "                        print()\n",
    "                else:\n",
    "                    print(\"No recommendations found matching your preferences.\")\n",
    "            else:\n",
    "                print(\"No movies found matching your preferences.\")\n",
    "        else:\n",
    "            print(\"OKAY.\")\n",
    "\n",
    "    elif keywords:\n",
    "        # handle user keywords\n",
    "        matched_movies = match_movies_by_keywords(keywords, movie_titles)\n",
    "        if matched_movies:\n",
    "            recommended_movie_ids = get_content_based_recommendations(matched_movies, similarity_matrix, movie_ids)\n",
    "            if recommended_movie_ids:\n",
    "                # display recommended movie details to the user\n",
    "                print(\"Here are some recommended movies:\")\n",
    "                for movie_id in recommended_movie_ids:\n",
    "                    movie_details = get_movie_details(movie_id)\n",
    "                    print(f\"Title: {movie_details['title']}\")\n",
    "                    print(f\"Genre: {movie_details['genre']}\")\n",
    "                    print(f\"Actors: {movie_details['actors']}\")\n",
    "                    print(f\"Director: {movie_details['director']}\")\n",
    "                    print(f\"Summary: {movie_details['summary']}\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"No recommendations found for the given keywords.\")\n",
    "        else:\n",
    "            # fuzzy matching to find close matches\n",
    "            matched_movies = match_movies_by_keywords(keywords, preprocessed_attributes, movie_titles)\n",
    "            if matched_movies:\n",
    "                recommended_movie_ids = get_content_based_recommendations(matched_movies, similarity_matrix, movie_ids)\n",
    "                if recommended_movie_ids:\n",
    "                    print(\"Here are some recommended movies based on similar titles:\")\n",
    "                    for movie_id in recommended_movie_ids:\n",
    "                        movie_details = get_movie_details(movie_id)\n",
    "                        print(f\"Title: {movie_details['title']}\")\n",
    "                        print(f\"Genre: {movie_details['genre']}\")\n",
    "                        print(f\"Actors: {movie_details['actors']}\")\n",
    "                        print(f\"Director: {movie_details['director']}\")\n",
    "                        print(f\"Summary: {movie_details['summary']}\")\n",
    "                        print()\n",
    "                else:\n",
    "                    print(\"No recommendations found for similar movie titles.\")\n",
    "            else:\n",
    "                print(\"No movies found matching the given keywords.\")\n",
    "    else:\n",
    "        # no movie preference or keywords detected\n",
    "        print(\"I'm sorry, I couldn't understand your request. Could you please provide more information?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
